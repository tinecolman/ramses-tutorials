{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dense core collapse with RAMSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document is aimed as a tutorial to explore the physics of the protostellar collapse using the RAMSES code. If you have never used RAMSES, you can take a look at the [RAMSES fundamentals tutorial](https://ramses-tutorials.readthedocs.io/en/latest/Fundamentals/tutorial.html). Otherwise you can proceed directly with this tutorial.\n",
    "\n",
    "Once you have installed RAMSES, in a Terminal, export the proper path to the `bin` directory, and to the directory where you have downloaded this tutorial:\n",
    "\n",
    "```bash\n",
    "export RAMSESPATH=/path/to/ramses/bin/\n",
    "export TUTOPATH=/path/to/this/tutorial/where/you/will/run/the/simulations\n",
    "```\n",
    "\n",
    "You are now ready to begin this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Star formation is a complex problem which invokes a huge range of scales, physical processes (MHD, radiation, self-gravity etc.) and components (gas, dust, photons etc.). In this project, we are going to investigate a particular problem of star formation, which is the gravitational collapse of dense cores (or prestellar cores) which occurs when they reach their Jeans mass. This process is at the origin of star formation and also, around the star and through angular momentum conservation, protostellar disk formation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Collapse setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Generalities\n",
    "As often when studying the interstellar medium (ISM), the question of initial conditions is tricky. In the collapse case we should, in principle start from very large scales (arguably galactic scales) and zoom-in up to dense core scales. While some groups are investigating this problem, this is of course not possible for a practical session. Therefore we are going to use a much simple set of initial conditions: the Boss and Bodenheimer setup ([Boss & Bodenheimer 1979](https://ui.adsabs.harvard.edu/#abs/1979ApJ...234..289B/abstract)).\n",
    "\n",
    "In this setup, we consider an isolated spherical dense core of mass M, radius R and temperature T. Generally, we fix the mass and temperature and compute the radius to ensure that the cloud is gravitationally collapsing. Often, we fix the radius using the thermal-to-gravitational energy ratio $\\alpha$ (or Virial parameter).\n",
    "\n",
    "$\\alpha = \\frac{5}{2} \\frac{R}{GM} \\frac{k_B T}{\\mu_g m_H}$\n",
    "\n",
    "where $G$ and $k_B$ are the gravitational and Boltzmann constants and $\\mu_g=2.31$ is the mean molecular weight. We usually the fix the simulation box size to be four times the cloud radius.\n",
    "\n",
    "\n",
    "You can also add some solid body rotation $\\Omega$, assuming a certain value for rotational-to-gravitational energy ratio $\\beta$. To initialize $\\Omega$, we define \n",
    " $\\beta$ such as \n",
    "\n",
    "\n",
    "$\\beta =\\frac{R^3 \\Omega^2}{3 \\mathcal{G} M_{\\odot} }$\n",
    "\n",
    "\n",
    "Typically, we set it to a few percent, which is in lines with observations of prestellar cores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Equation of state \n",
    "\n",
    "The radiative transfer during the collapse is, in principle, a quite complex business and requires to use a  radiative transfer (RT) solver which is able to treat properly infrared radiation. We often circumvent the issue by assuming a barotropic equation of state (EOS) as follows\n",
    "\n",
    "$P = \\rho c_{s,0}^2 \\left[1 + \\left(\\frac{\\rho}{\\rho_{\\mathrm{ad}}}\\right)^{\\gamma-1}\\right]$\n",
    "\n",
    "\n",
    "This equation allows to recover the two regimes of the first collapse, namely the isothermal phase at low density when radiation can escape freely from the core in the infrared (IR) and the adiabatic contraction of the first Larson core at high density ($\\rho>\\rho_{\\mathrm{ad}}\\simeq 10^{-13} \\rm{g/cm}^3$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Parameter file (the namelist)\n",
    "\n",
    "Here is a summary of the most important parameters that are relevant for collapse calculations. You have to set them in your nml file prior running the simulation.  Note that you can find information on all the other namelist parameters you can play with here: https://ramses-organisation.readthedocs.io/en/latest/wiki/Runtime_Parameters.html\n",
    "\n",
    "1. `RUN_PARAMS`. This section defines some of the most basic properties of the run, and the important ones for us here are the following:\n",
    "```\n",
    "hydro=.true.    ! We solve the hydro equations \n",
    "poisson=.true.  ! We solve the Poisson equation\n",
    "nrestart=0      ! This not a restart. Set to i (the output i) to restart\n",
    "nremap=10       ! We do the load balancing every 10 dt. This should be reduced for big runs.\n",
    "nsubcycle=6*1,2 ! We do sub cycling but not for the 6 first level of refinement (starting from lmin)\n",
    "```\n",
    "\n",
    "2. `AMR_PARAMS`. This defines the global mesh properties and memory footprint of the code with the following parameters:\n",
    "```\n",
    "levelmin=5             ! this is the lowest level (same that in the initial conditions).\n",
    "levelmax=15            ! This is the maximum level of refinement level allowed. \n",
    "ngridmax=1000000       ! This is the maximum number of grids (oct) that we allow\n",
    "nexpand=2              ! is the smoothing of the grid at the boundary between levels\n",
    "boxlen=1.              ! This is the box size in code units (this value should be set carefully, see below)\n",
    "```\n",
    "\n",
    "3. `BOUNDARY_PARAMS` tells RAMSES what boundary conditions to use. By default, periodic boundaries are used. Here this is zero gradients \n",
    "```\n",
    "nboundary = 6\n",
    "bound_type= 2, 2, 2, 2, 2, 2\n",
    "ibound_min=-1,+1,-1,-1,-1,-1\n",
    "ibound_max=-1,+1,+1,+1,+1,+1\n",
    "jbound_min= 0, 0,-1,+1,-1,-1\n",
    "jbound_max= 0, 0,-1,+1,+1,+1\n",
    "kbound_min= 0, 0, 0, 0,-1,+1\n",
    "kbound_max= 0, 0, 0, 0,-1,+1\n",
    "```\n",
    "\n",
    "4. `INIT_PARAMS` tells RAMSES about the initial conditions we want to set.\n",
    "\n",
    "```\n",
    "condinit_kind='collapse' ! Sets the kind of initial collapse\n",
    "alpha_dense_core=0.35    ! Sets the thermal-to-gravitational ratio (fixing the cloud radius for a given temperature)\n",
    "beta_dense_core=0.0      ! Sets the amount of rotation\n",
    "crit_dense_core=0.0      ! Sets the inverse mass-to-flux ratio (the criticality of the core)\n",
    "delta_rho=0.0            ! Sets the amplitude of the m=2 density perturbation\n",
    "theta_mag=0.             ! Sets the angle in degrees between the magnetic and rotation axis\n",
    "```\n",
    "\n",
    "\n",
    "5. `OUTPUT_PARAMS` defines the output strategy. Here we make a snapshot evrery 50 dt and also dump the ouptuts of the tout array (times are in code units).\n",
    "\n",
    "```\n",
    "foutput=50 \n",
    "noutput=4\n",
    "tout=0,1,2,3\n",
    "```\n",
    "\n",
    "6. `POISSON_PARAMS` defines the parameters for gravity\n",
    "\n",
    "```\n",
    "gravity_type=0 ! We solve self-gravity\n",
    "epsilon=1d-4   ! Tolerance for the error on the gravitational potential\n",
    "cg_levelmin=7  ! Minimum level from which the Conjugate Gradient solver is used in place of the Multigrid solver\n",
    "```\n",
    "\n",
    "7. `HYDRO_PARAMS` defines the parameters for the hydrodynamics\n",
    "\n",
    "```\n",
    "gamma=1.666667      ! Adiabatic index\n",
    "courant_factor=0.8  ! Safety factor for the courant conditions, sets the timestep (>1 is unstable)\n",
    "slope_type=1        ! Slope limiter for the predictor corrector. 1= minmod\n",
    "scheme='muscl'      ! Scheme to solve the hydro\n",
    "riemann='llf'       ! Riemann solver. Good options are llf, hll, hllc.\n",
    "```\n",
    "\n",
    "8. `UNIT_PARAMS` defines the constants to be used to convert values from code unit to cgs\n",
    "\n",
    "```\n",
    "units_density= 3.83584509e-24      ! so that density in code units is equal to density in part/cc\n",
    "units_length= 3.0856776e+18        ! 1 pc in cm\n",
    "units_time= 1.9769994708456518e15  ! so that G=1 in code units\n",
    "```\n",
    "\n",
    "9. `COOLING_PARAMS` defines the barotropic EOS\n",
    "\n",
    "```\n",
    "barotropic_eos=.true.\n",
    "barotropic_eos_form='double_polytrope' ! type of barotropic eos\n",
    "polytrope_rho=1d-13                    ! sets rho_ad in EOS, in g/cm3\n",
    "polytrope_index=1.666667               ! sets gamma in EOS\n",
    "T_eos=10d0                             ! sets T0 in EOS, in K\n",
    "mu_gas=2.31d0                          ! molecular weight\n",
    "```\n",
    "\n",
    "10. `REFINE_PARAMS` defines the refinement strategy. Here we implement a Jeans-length based refinement, where any cell with more than 20 points per Jeans length for 10 successive levels\n",
    "\n",
    "```\n",
    "jeans_refine=20*10. ! Jeans refinement strategy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide a `barotrop.nml` file which will be the basis for this tutorial. This file will need to be adapted to the specific initial conditions you want to use. To do so, we provide below a routine `setup_nml` which computes the different namelist parameters to be changed accordingly when fixing $\\alpha$, $M$, $T$, and the output times.\n",
    "\n",
    "In all the simulations below, we will use $\\alpha=0.35$, $M=1\\,M_\\odot$, $T=10\\,\\mathrm{K}$, and $t_{\\rm out}=0.,0.25,0.5,0.75,1,1.25,1.5$ t$_{\\rm ff}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def setup_nml(alpha_dense_core=0.1,mass_c=1.,T_eos=10,tout=(0,1)):\n",
    "    ''' \n",
    "    alpha_dense_core  : cloud virial parameter, thermal-to-gravitational energy\n",
    "    mass_c            : cloud mass in solar mass\n",
    "    T_eos             : cloud temperature\n",
    "\n",
    "    tout              : output times in free-fall time units\n",
    "    '''\n",
    "    \n",
    "    # from RAMSES amr/constants.f90 file\n",
    "    mH=1.6605390e-24      # H atom mass [g] = amu, i.e. atomic mass unit; NIST\n",
    "    kB=1.3806490e-16      # Boltzmann const. [erg K-1]; SI\n",
    "    M_sun = 1.9891000e+33 # Solar Mass [g]; IAU\n",
    "\n",
    "    pc2cm   = 3.0856776e+18  # pc [cm]\n",
    "    kyr2sec = 3.15576000e+10 # Kyr [s]\n",
    "\n",
    "    G=6.67e-8 # Gravitational constant in cgs [cm3 g-1 s-2]\n",
    "    \n",
    "    mu_gas=2.31           # Mean molecular weigth\n",
    "\n",
    "    units_length=pc2cm                      # 1 pc in cm\n",
    "    units_density=mu_gas*mH                 # so that density in code units is equals to density in part/cc\n",
    "    units_time=1./np.sqrt(G*units_density)  # so that G=1 in code units\n",
    "\n",
    "    scale_d = units_density\n",
    "    scale_t = units_time\n",
    "    scale_l = units_length\n",
    "    scale_m=scale_d*scale_l**3\n",
    "    \n",
    "    mass_c_cu = mass_c * (M_sun / scale_m ) # cloud mass in code units\n",
    "    \n",
    "    r0=(alpha_dense_core*2.*G*mass_c_cu*scale_m*mu_gas*mH/(5.*kB*T_eos))/scale_l\n",
    "    boxlen=4*r0\n",
    "    d0=3.0*mass_c_cu/(4.0e0*np.pi*r0**3.)\n",
    "    \n",
    "    tff=np.sqrt(3*np.pi/(32*G*d0*scale_d))/scale_t\n",
    "\n",
    "    print('Cloud size in code units, and in pc=',r0,r0*scale_l/3.0856776e+18)\n",
    "    print('  box size in code units, and in pc=',boxlen,boxlen*scale_l/3.0856776e+18)\n",
    "    print('Free-fall time in code units, and in kyr=',tff,tff*scale_t/3.15576000e+10)\n",
    "    print()\n",
    "    print('Values to be put in the namelist')\n",
    "    print('In UNITS_PARAMS')\n",
    "    print('   units_density=',units_density)\n",
    "    print('   units_length=',units_length)\n",
    "    print('   units_time=',units_time)\n",
    "    print('In AMR_PARAMS')\n",
    "    print('   boxlen=',boxlen)\n",
    "    print('In OUTPUT_PARAMS')\n",
    "    print('   tout=', ', '.join(str(t*tff) for t in tout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_nml()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. A quick first collapse model : exploration of the first Larson core "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Hydro collapse without rotation\n",
    "\n",
    "Let's now run a first collapse calculation with the aim of writing a python pipeline to analyse it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform this analysis we will use the documentation of Osyris (available at https://osyris.readthedocs.io/en/stable/).\n",
    "\n",
    "To run our calculation we first need to compile the code\n",
    "\n",
    "```bash\n",
    "cd $RAMSESPATH\n",
    "make clean\n",
    "make SOLVER=mhd NDIM=3 MPI=1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have now a `ramses3d` executable that can be used to run collapse calculations (using the correct namelist).\n",
    "\n",
    "Now you will have to copy the executable and the namelist file into the collapse-run directory where you want to run the simulation. Once it's done you can go in this directory. Let's assume you want to run the code with 4 CPUs, then the commands are simply \n",
    "\n",
    "```bash\n",
    "cd $TUTOPATH\n",
    "mkdir RUN1\n",
    "cp $RAMSESPATH/ramses3d RUN1\n",
    "cp barotrop.nml RUN1\n",
    "cd RUN1\n",
    "mpirun -np 4 ramses3d barotrop.nml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can keep the terminal information in a log file (e.g. collapse.log) with the command. To do so, replace the last command by\n",
    "\n",
    "```bash\n",
    "mpirun -np 4 ramses3d barotrop.nml > collapse.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now analyse this first simulation by performing 100 au x 100 au slices in the x,y and z directions. You should have the following results.\n",
    "\n",
    "<div>\n",
    "<img src=\"figures/run1_slice_x.png\" alt=\"run1_slice_x\" width=\"225\"/>\n",
    "<img src=\"figures/run1_slice_y.png\" alt=\"run1_slice_y\" width=\"225\"/>\n",
    "<img src=\"figures/run1_slice_z.png\" alt=\"run1_slice_z\" width=\"225\"/>\n",
    "</div>\n",
    "\n",
    "As can be seen in these figures, in this particular case of a collapse without rotation, the first Larson core remains mostly spherical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osyris\n",
    "import numpy as np\n",
    "au = osyris.units(\"au\")\n",
    "data = osyris.RamsesDataset(10, path='RUN1').load() # Change this path to the path of the model\n",
    "# We find the center according to the density\n",
    "ind = np.argmax(data[\"mesh\"][\"density\"])\n",
    "center = data[\"mesh\"][\"position\"][ind]\n",
    "osyris.map(\n",
    "    data[\"mesh\"].layer(\"density\"), norm=\"log\", dx=100 * au, origin=center, direction=\"x\"\n",
    ")\n",
    "osyris.map(\n",
    "    data[\"mesh\"].layer(\"density\"), norm=\"log\", dx=100 * au, origin=center, direction=\"y\"\n",
    ")\n",
    "osyris.map(\n",
    "    data[\"mesh\"].layer(\"density\"), norm=\"log\", dx=100 * au, origin=center, direction=\"z\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Making movies\n",
    "\n",
    "The RAMSES simulation namelist contains a block MOVIE_PARAMS (see also [the documentation](https://ramses-organisation.readthedocs.io/en/latest/wiki/Movies.html) for details), which tells the code to generate binary files with short time intervals showing face-on and edge-on projections of gas density at different zooms.\n",
    "\n",
    "The first cell below reads those binary files and creates .png images out of them.\n",
    "\n",
    "The second cell then calls ffmpeg to squeeze all those pngs into one .mp4 movie file. For that second cell to work, you need to have [ffmpeg](https://www.ffmpeg.org) installed.\n",
    "\n",
    "To download and install ffmpeg, you can use a package manager such as `sudo apt install ffmpeg` (Ubuntu), `brew install ffmpeg` (Mac OS), or load it through a module `module load ffmpeg` (e.g. on a cluster).\n",
    "\n",
    "As a last resort, you may compile it from source as follows:\n",
    "  ```bash\n",
    "  git clone https://git.ffmpeg.org/ffmpeg.git ffmpeg\n",
    "  cd ffmpeg\n",
    "  ./configure\n",
    "  make\n",
    "  make install\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read binary movie frames and make .png images\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from scipy.io import FortranFile\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.patches as mpatches\n",
    "from tqdm import tqdm \n",
    "\n",
    "def create_png_for_movie(path='.',movie_number=1):\n",
    "    if movie_number == 1:\n",
    "        bar_length_to_be_plot = 1000\n",
    "    elif movie_number == 2:\n",
    "        bar_length_to_be_plot = 100\n",
    "    elif movie_number == 3:\n",
    "        bar_length_to_be_plot = 100\n",
    "    else:\n",
    "        print('Bad value for variable movie_number')\n",
    "    \n",
    "    plt.ioff() # So as not to show plots\n",
    "    #plt.ion() # So as to show plots\n",
    "    fig = plt.figure(frameon=False)\n",
    "    nx = 1920\n",
    "    ny = 1080\n",
    "    nypic=ny  #int(ny*0.6)\n",
    "    plt.subplots_adjust(left=0., bottom=0.,\n",
    "                    right=1.+1.0/nx, top=1.+1.0/nypic,\n",
    "                    wspace=0., hspace=0.)\n",
    "    fig.set_size_inches(nx/100.*.7,nypic/100.*.7)\n",
    "\n",
    "    #As defined via movie_vars_txt in setup.nml\n",
    "    quants = {\n",
    "        \"dens\": {\n",
    "            \"name\": \"dens\",\n",
    "            \"data\": np.array([]),\n",
    "            \"min\": 1e6,\n",
    "            \"max\": -1e10,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    d_cmap=matplotlib.cm.viridis\n",
    "\n",
    "    movie_path = '%s/movie%d/'%(path,movie_number)\n",
    "    png_dir = '%s/pngs'%(path)\n",
    "    try:\n",
    "        os.mkdir(png_dir) # Create directory to store movie frames in png files\n",
    "    except FileExistsError:\n",
    "        do_nothing=True\n",
    "    all_ok = True\n",
    "\n",
    "    # Figure out the number of frames for the movie\n",
    "    searchstring = '%s/info_'%(movie_path)\n",
    "    frames = glob.glob(searchstring+'*') # Frame strings\n",
    "    i_frames = [ int(str[len(searchstring):len(searchstring)+4]) for str in frames ]\n",
    "    i_frames = sorted(i_frames)         # Sort them\n",
    "    imin = i_frames[0]\n",
    "    imax = i_frames[len(i_frames)-1]\n",
    "\n",
    "    # Loop over the movie frames and generate .png images\n",
    "    for i in tqdm(range(imin,imax+1)):\n",
    "        # Read the info file:\n",
    "        try:\n",
    "            info = open(f\"{movie_path}info_{str(i).zfill(5)}.txt\").readlines()\n",
    "            pass\n",
    "        except:\n",
    "            continue\n",
    "        time_sec=0.0\n",
    "        time_sec = float(info[8].split(\"=\")[-1].strip())\n",
    "        unit_l =   float(info[15].split(\"=\")[-1].strip())\n",
    "        unit_d =   float(info[16].split(\"=\")[-1].strip())\n",
    "        unit_t =   float(info[17].split(\"=\")[-1].strip())\n",
    "        time_kyr = time_sec*unit_t/3.156e10\n",
    "    \n",
    "        # Load in the data\n",
    "        for q in quants:\n",
    "            fname = f\"{quants[q]['name']}_{str(i).zfill(5)}.map\"\n",
    "            ffile = FortranFile(f\"{movie_path}{fname}\")\n",
    "            [time, fdw, fdh, fdd] = ffile.read_reals('d')\n",
    "            [frame_nx, frame_ny] = ffile.read_ints()\n",
    "            data = np.array(ffile.read_reals('f4'), dtype=np.float64)\n",
    "            try: \n",
    "                quants[q][\"data\"] = data.reshape(frame_nx,frame_ny)\n",
    "                quants[q][\"min\"] = quants[q][\"data\"][quants[q][\"data\"] > 0].min()\n",
    "                quants[q][\"max\"] = quants[q][\"data\"][quants[q][\"data\"] > 0].max()\n",
    "                quants[q][\"data\"][quants[q][\"data\"] < quants[q][\"min\"]] = 1e-5 * quants[q][\"min\"]\n",
    "            except ValueError:\n",
    "                all_ok = False\n",
    "            f, axs = plt.subplots(1,1,figsize=(7.5,7.5),sharex=True,sharey=True)\n",
    "        plt.subplots_adjust(left=0, right=1.0, top=1.0, bottom=0)\n",
    "        axs.imshow(np.log10(quants[\"dens\"][\"data\"]),vmin=4,vmax=12,cmap=d_cmap,aspect='auto',interpolation='none')\n",
    "        plt.axis(\"off\")\n",
    "        # Text showing simulation time\n",
    "        axs.text(0.97, 0.03,'%.2f kyr'%(time_kyr), fontsize=15,transform=axs.transAxes\n",
    "             , verticalalignment='bottom', horizontalalignment='right', color='white')\n",
    "        # Bar showing length scale\n",
    "        frame_width_au = fdw*unit_l/1.496e+13\n",
    "        rect = mpatches.Rectangle((0.055,0.03),bar_length_to_be_plot/frame_width_au,0.002,color='white',transform=axs.transAxes)\n",
    "        axs.add_patch(rect)\n",
    "        axs.text(0.055, 0.01+15./frame_ny, ('%d au'%(bar_length_to_be_plot)),\n",
    "            verticalalignment='bottom', horizontalalignment='left',\n",
    "            transform=axs.transAxes, color='white', fontsize=15. )\n",
    "   \n",
    "        # Store frame in png file\n",
    "        filename = '%s/frame_%d_%05d.png'%(png_dir,movie_number,i)\n",
    "        #print(filename)\n",
    "        f.savefig(filename, dpi=100)\n",
    "        plt.close()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ffmpeg to make a .mp4 out of the .png frames\n",
    "import subprocess\n",
    "\n",
    "def create_mp4_from_png(path='.',movie_number=1):\n",
    "    movie_filename = '%s/movie%d.mp4'%(path,movie_number)\n",
    "    frames = '%s/pngs/frame_%d_%%*.png'%(path,movie_number)\n",
    "    fps=50.\n",
    "    speed=60.\n",
    "    quality=23\n",
    "    print(\"Calling ffmpeg! Output: {mov}\".format(mov=movie_filename))\n",
    "    print(\"{binffmpeg} -i {input}\\\n",
    "                     -y -vcodec h264 -pix_fmt yuv420p\\\n",
    "                     -r {fps} -filter:v 'setpts={speed}*PTS'\\\n",
    "                     -crf {quality} {output}\".\n",
    "                    format(binffmpeg='ffmpeg', input=frames,\n",
    "                           fps=fps, speed=speed/fps,\n",
    "                           quality=quality, output=movie_filename))\n",
    "    subprocess.call(\"{binffmpeg} -i {input}\\\n",
    "                     -y -vcodec h264 -pix_fmt yuv420p\\\n",
    "                     -r {fps} -filter:v 'setpts={speed}*PTS'\\\n",
    "                     -crf {quality} {output}\".\n",
    "                    format(binffmpeg='ffmpeg', input=frames,\n",
    "                           fps=fps, speed=60./fps,\n",
    "                           quality=quality, output=movie_filename), shell=True)\n",
    "    print('####################################################################')\n",
    "    print('-----------Your new movie is here: ', movie_filename)\n",
    "    print('####################################################################')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='RUN1'\n",
    "movie_number = 2 # movie ID #################### CHANGE THIS FOR THE 3 DIFFERENT MOVIES\n",
    "\n",
    "create_png_for_movie(path,movie_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_mp4_from_png(path,movie_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 More fun "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> Before you do this analysis, you should start the next simulations which take a longer time to complete.</span> \n",
    "\n",
    "\n",
    "We can now start to extract structures (such as the first core) to analyse the model. When the density reaches values higher than $10^{-11}\\,\\mathrm{g\\,cm^{-3}}$, fragments called first Larson cores are forming. We propose to measure the mass as a function of time. This will require to filter the data with masks (using the criterion $\\rho>10^{-11}\\,\\mathrm{g\\, cm^{-3}}$) and to perform the mass measurement on these filtered data.\n",
    "You can try to play with the initial cloud mass to see if it impacts or not the mass of the First larson core.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Adding rotation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now add rotation to the previous setup (you should run these new simulations in a new directory, e.g. `RUN2`). The solid body rotation rate is controlled with the beta\\_dense\\_core parameter. Typically, you can choose a value between 0.01 and 0.05 to stay in the observed range of dense core (the image of the tutorial is done with 0.05). You should also set delta\\_rho to 0.1. This sets a m=2 density perturbation of 10\\% amplitude which prevent the formation of a spurious m=4 mode which could unfortunately form as a consequence of the cartesian grid. \n",
    "\n",
    "Let's now play with this parameter and see its impact on the fragmentation and disk formation during the collapse. For that, we need to push a bit the calculation, as fragmentation will not happen immediately. We will need to run the simulation at least up to output 16 (more ore less a few depending on your choice of initial conditions). If time is limited, we can distribute some outputs to analyse them once you have run the first timesteps yourself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 500 au x 500 au slice in the z and y direction obtained with OSYRIS for the snapshot 16 centered at the position of the density maximum should look like this\n",
    "\n",
    "<div>\n",
    "<img src=\"figures/run2_slice_x.png\" alt=\"run2_slice_x\" width=\"325\"/>\n",
    "<img src=\"figures/run2_slice_z.png\" alt=\"run2_slice_z\" width=\"325\"/>\n",
    "</div>\n",
    "\n",
    "With the z-slice, we clearly see that the core has fragmented into several objects. With the x-slice, it also becomes clear that matter is organised in a thin disk-like rotationally supported structure which is the consequence of angular momentum conservation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osyris\n",
    "import numpy as np\n",
    "au = osyris.units(\"au\")\n",
    "data = osyris.RamsesDataset(16, path='RUN2').load() # Change this path to the path of the model\n",
    "# We find the center according to the density\n",
    "ind = np.argmax(data[\"mesh\"][\"density\"])\n",
    "center = data[\"mesh\"][\"position\"][ind]\n",
    "osyris.map(\n",
    "    data[\"mesh\"].layer(\"density\"), norm=\"log\", dx=500 * au, origin=center, direction=\"z\"\n",
    ")\n",
    "\n",
    "osyris.map(\n",
    "    data[\"mesh\"].layer(\"density\"), norm=\"log\", dx=500 * au, origin=center, direction=\"x\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More fun "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can count the fragment, look at their separation as a function of time and their mass distribution as a function of the rotation rate, the density perturbation.\n",
    "It is also interesting to look at the disk properties, when a disk is formed. For that we need to have some seletion criterion for the disk. Typically, we consider that a disk is a dense and rotationally supported structure. To extract it, we can use the following criterion. The disk material must be \n",
    "1. Dense enough.\n",
    "2. Supported by rotation\n",
    "3. Not thermally supported (this is the first core).\n",
    "\n",
    "Once you have extracted the disk, try to measure its size and mass as a function of the time. You can also play with the extraction parameters.\n",
    "\n",
    "The same figure as before but with the disk selection should look like this:\n",
    "\n",
    "<img src=\"figures/run2_disk_slice_z.png\" alt=\"run2_disk_slice_z\" />\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osyris\n",
    "import numpy as np\n",
    "au = osyris.units(\"au\")\n",
    "data = osyris.RamsesDataset(16, path='./RUN2/').load() # Change this path to the path of the model\n",
    "# We find the center according to the density\n",
    "ind = np.argmax(data[\"mesh\"][\"density\"])\n",
    "center = data[\"mesh\"][\"position\"][ind]\n",
    "condition = (data[\"mesh\"][\"density\"] < (5.0e-14 * osyris.units(\"g/cm**3\"))) | (\n",
    "    data[\"mesh\"][\"density\"] > (5.0e-12 * osyris.units(\"g/cm**3\"))\n",
    ")\n",
    "data[\"mesh\"][\"disk_density\"] = osyris.Array(\n",
    "    np.ma.masked_where(condition.values, data[\"mesh\"][\"density\"].values),\n",
    "    unit=data[\"mesh\"][\"density\"].unit,\n",
    ")\n",
    "osyris.map(data[\"mesh\"].layer(\"disk_density\"), dx=500 * au, norm=\"log\", origin=center,direction='z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Magnetic fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Aligned magnetic fields\n",
    "Dense core are actually magnetised, and the magnetic field, although likely sub-critical is likely to be dynamically relevant. Usually, we set the magnetic field strength according to the mass-to-flux ratio $\\mu$ (in units of critical mass-to-flux ratio): $ \\mu=\\frac{\\left(M/\\phi\\right)}{\\left(M/\\phi\\right)_{\\rm crit}}$, where $\\phi=\\pi B R^2$ and \n",
    "$\\left(M/\\phi\\right)_{\\rm crit}=\\frac{0.53}{3\\pi}\\sqrt{\\frac{5}{G}}$ ([Mouschovias & Spitzer 1976](https://ui.adsabs.harvard.edu/abs/1976ApJ...210..326M/abstract)).\n",
    "\n",
    "When $\\mu>1$, the collapse can happen, typically $1<\\mu<10$ in dense cores, so let's explore here this range. By setting the parameter crit_dense_core in the namelist, we are setting $\\frac{1}{\\mu}$. We can start to run a simulation with crit_dense_core=0.3, starting from the previous setup (run it in a new directory `RUN3`). For this value the magnetic field is important while not strong enough to stop the collapse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look again at the collapse seen face-one (z slice). Normally, you should see that for mass-to-flux ratio of the order of a few, the disk is gone. We can observe a dense thin structure around the first core but this is not a disk, this is a pseudo-disk. The pseudo-disk is a consequence of the pinching of the magnetic field line that compress the matter in the equatorial plane but it is not a supported structure (it is collapsing).\n",
    "\n",
    "Here is a 500 au x 500 au slice in the x direction obtained with OSYRIS that shows the pseudo-disk for a collapse model with crit_dense_core=0.3.\n",
    "\n",
    "<div>\n",
    "<img src=\"figures/run3_slice_x.png\" alt=\"run3_slice_x\" width=\"325\"/>\n",
    "<img src=\"figures/run3_slice_z.png\" alt=\"run3_slice_z\" width=\"325\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osyris\n",
    "import numpy as np\n",
    "au = osyris.units(\"au\")\n",
    "data = osyris.RamsesDataset(13, path='./RUN3/').load() # Change this path to the path of the model\n",
    "# We find the center according to the density\n",
    "ind = np.argmax(data[\"mesh\"][\"density\"])\n",
    "center = data[\"mesh\"][\"position\"][ind]\n",
    "osyris.map(\n",
    "    data[\"mesh\"].layer(\"density\"), norm=\"log\", dx=500 * au, origin=center, direction=\"z\"\n",
    ")\n",
    "\n",
    "osyris.map(\n",
    "    data[\"mesh\"].layer(\"density\"), norm=\"log\", dx=500 * au, origin=center, direction=\"x\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Why is the disk gone ? During the collapse, the twisting of the magnetic field lines generates an intense magnetic braking which suppresses rotation. This so-called magnetic braking catastrophe is a classic problem in the disk formation community. You can take a look at the magnetic field lines to see both the pinching and twisting on the field. \n",
    "\n",
    "\n",
    "\n",
    "This problem is now solved for the most part by including non-ideal MHD processes that decouple the gas from the magnetic field but are unfortunately not yet implemented in the public version of ramses. Two other potential solutions to recover the disks have also been brought-up by the community: a misalignment between the magnetic field and the rotation axis and turbulence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite interestingly, magnetised models also produce protostellar outflows, you will see them well if you integrate the model up to output 22. This is good since these outflows are observed. You can look at them with edge-one slices and try to see how they depend on the initial magnetic field strength.\n",
    "\n",
    "A 500 au x 500 au slice in the x direction obtained with OSYRIS that shows a MHD outflow for a collapse model with crit=0.3 as it propagates in the z direction:\n",
    "\n",
    "<img src=\"figures/run3_outflow_slice_x.png\" alt=\"run3_outflow_slice_x\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osyris\n",
    "import numpy as np\n",
    "au = osyris.units(\"au\")\n",
    "data = osyris.RamsesDataset(22, path='./RUN3/').load() # Change this path to the path of the model\n",
    "# We find the center according to the density\n",
    "ind = np.argmax(data[\"mesh\"][\"density\"])\n",
    "center = data[\"mesh\"][\"position\"][ind]\n",
    "\n",
    "osyris.map(\n",
    "        data[\"mesh\"].layer(\"density\", norm=\"log\"), \n",
    "        data[\"mesh\"].layer(\"velocity\", mode= \"vec\"), norm=\"log\", dx=500 * au, origin=center, direction=\"x\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Misaligned magnetic fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now pay attention to the case when the axis of rotation and of the magnetic field are misaligned. This angle is controlled by the `theta_mag` parameter in the namelist.\n",
    "We can start with a value of 60 degrees (you should run the simulation in a new directory, e.g. `RUN4`). \n",
    "\n",
    "Let's </span> look at the result early on (output 10) at a relatively large scale. We can see that the flow is tilted with respect to the the z axis because the rotation axis is not z anymore but is tilted by the angle theta_mag.\n",
    "\n",
    "A 5000 au x 5000 au slice in the y direction obtained with OSYRIS (left panel) shows that the axis of rotation is now tilted by 60 degrees. We can redo the same figure, but making it perpendicular to the new rotation axis thanks to the functionality of osyris which can find the angular momentum axis (right panel).\n",
    "\n",
    "<div>\n",
    "<img src=\"figures/run4_slice_y.png\" alt=\"run4_slice_y\" width=\"325\"/>\n",
    "<img src=\"figures/run4_slice_top.png\" alt=\"run4_slice_top\" width=\"325\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osyris\n",
    "import numpy as np\n",
    "au = osyris.units(\"au\")\n",
    "data = osyris.RamsesDataset(7, path='./RUN4/').load() # Change this path to the path of the model\n",
    "# We find the center according to the density\n",
    "ind = np.argmax(data[\"mesh\"][\"density\"])\n",
    "center = data[\"mesh\"][\"position\"][ind]\n",
    "\n",
    "osyris.map(\n",
    "        data[\"mesh\"].layer(\"density\",norm=\"log\"), \n",
    "        data[\"mesh\"].layer(\"velocity\",mode=\"vec\"), norm=\"log\", dx=5000 * au, origin=center, direction='y'\n",
    "    #,filename='run4_slice_y.png'\n",
    ")\n",
    "\n",
    "osyris.map(\n",
    "        data[\"mesh\"].layer(\"density\",norm=\"log\"), \n",
    "        data[\"mesh\"].layer(\"velocity\",mode=\"vec\"), norm=\"log\", dx=5000 * au, origin=center, direction='top'\n",
    "    #,filename='run4_slice_top.png'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now wait a bit longer, and make a 'top' slice i.e. a slice in the rotation plane we can see that we now recover a disk.\n",
    "\n",
    "<div>\n",
    "<img src=\"figures/run4_slice_top_longer.png\" alt=\"run4_slice_top_longer.png\" width=\"325\"/>\n",
    "<img src=\"figures/run4_slice_top_longer_disk.png\" alt=\"run4_slice_top_longer_disk.png\" width=\"325\"/>\n",
    "</div>\n",
    "\n",
    "We can play the same game as before (measuring its properties) and also test the disk properties as a function of the angle between the magnetic field and rotation. \n",
    "An interesting question might be: which is the limit angle to form a disk for a given magnetic field strenght?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osyris\n",
    "import numpy as np\n",
    "au = osyris.units(\"au\")\n",
    "data = osyris.RamsesDataset(18, path='./RUN4/').load() # Change this path to the path of the model\n",
    "# We find the center according to the density\n",
    "ind = np.argmax(data[\"mesh\"][\"density\"])\n",
    "\n",
    "center = data[\"mesh\"][\"position\"][ind]\n",
    "\n",
    "osyris.map(\n",
    "        data[\"mesh\"].layer(\"density\",norm=\"log\"), \n",
    "        data[\"mesh\"].layer(\"velocity\",mode=\"vec\"), norm=\"log\", dx=100 * au, origin=center, direction='top'\n",
    "    #,filename='run4_slice_top_longer.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osyris\n",
    "import numpy as np\n",
    "au = osyris.units(\"au\")\n",
    "data = osyris.RamsesDataset(18, path='./RUN4/').load() # Change this path to the path of the model\n",
    "# We find the center according to the density\n",
    "ind = np.argmax(data[\"mesh\"][\"density\"])\n",
    "\n",
    "center = data[\"mesh\"][\"position\"][ind]\n",
    "condition = (data[\"mesh\"][\"density\"] < (5.0e-14 * osyris.units(\"g/cm**3\"))) | (\n",
    "    data[\"mesh\"][\"density\"] > (5.0e-12 * osyris.units(\"g/cm**3\"))\n",
    ")\n",
    "data[\"mesh\"][\"disk_density\"] = osyris.Array(\n",
    "    np.ma.masked_where(condition.values, data[\"mesh\"][\"density\"].values),\n",
    "    unit=data[\"mesh\"][\"density\"].unit,\n",
    ")\n",
    "osyris.map(data[\"mesh\"].layer(\"disk_density\"), dx=100 * au, norm=\"log\", origin=center, direction='z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initial turbulence\n",
    "\n",
    "In order to take into account the interstellar turbulence in the initial conditions, another parameter can be used. The `Mach` parameter in the `INIT_PARAMS` block of the namelist sets the initial Mach number of a turbulent initial velocity field, which is added to the one set up by `beta_dense_core` if specified.\n",
    "\n",
    "You can play around with this parameter to see its influence. In particular, you can see that with a high value of `Mach` the turbulent support can prevent the collapse.\n",
    "\n",
    "Note that to do so, you will need a file `init_turb.data` which contains the initial turbulent velocity field. To generate such a file, you can use the script below, where you will have to specify 3 random number seeds and the value of the power-law index. (Note that if not done yet, you will have to install the `turbustat` package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install turbustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turbustat.simulator import make_3dfield\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# choose random number seeds\n",
    "# choose powerlaw index\n",
    "# empirically Gaussian fluctuations power law (modelled by the fBm) is about 3.4 - 3.6 (J.-F. Robitaille)\n",
    "\n",
    "def generate_init_turb(seed1=824329,seed2=129862,seed3=786276,powerlaw=3.5):\n",
    "    # choose name for output file\n",
    "    filename = 'ramses_{}-{}-{}.data'.format(seed1, seed2, seed3)\n",
    "\n",
    "    # generate fields for the three components of the velocity\n",
    "    cells=100\n",
    "    vx = make_3dfield(cells, powerlaw=powerlaw, randomseed=seed1)\n",
    "    vy = make_3dfield(cells, powerlaw=powerlaw, randomseed=seed2)\n",
    "    vz = make_3dfield(cells, powerlaw=powerlaw, randomseed=seed3)\n",
    "    # make plots to verify the fields look OK\n",
    "    for seed, v in zip([seed1, seed2, seed3], [vx,vy,vz]):\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=3, figsize=[10, 3])\n",
    "        ax[0].imshow(v.mean(0), origin='lower')\n",
    "        ax[1].imshow(v.mean(1), origin='lower')\n",
    "        ax[2].imshow(v.mean(2), origin='lower')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('seed{}_pl{}.png'.format(seed, powerlaw))\n",
    "        plt.close()\n",
    "\n",
    "    # write fields to ramses readable ascii file\n",
    "    f = open(filename, 'w')\n",
    "    f.write('{:8}{:13.5f}{:13.5f}{:13.5f}{:13.5f}\\n'.format(cells, powerlaw, seed1, seed2, seed3))\n",
    "    for x in range(cells):\n",
    "        for y in range(cells):\n",
    "            for z in range(cells):\n",
    "                f.write('{:13.5f}{:13.5f}{:13.5f}{:13.5f}{:13.5f}{:13.5f}\\n'.format(x, y, z, vx[x,y,z], vy[x,y,z], vz[x,y,z]))\n",
    "    f.close()\n",
    "    print('\\033[92m' + 'Initial turbulent field ' + filename + ' generated\\033[0m')\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_init_turb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once done, then simply rename the generated file to `init_turb.data` and copy it into the directory where you will run the simulations (e.g. `RUN5`).\n",
    "\n",
    "```bash\n",
    "    cp ramses_824329-129862-786276.data RUN5/init_turb.data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## A non exhaustive list of collapse papers with RAMSES\n",
    "\n",
    "If you want to dig deeper in the collapses with RAMSES, here is a list of some (but biased and not at all exhaustive) of the papers that were written using this setup (generally with a modified version including more physics):\n",
    "\n",
    "1. [Hennebelle and Fromang 2008](https://ui.adsabs.harvard.edu/abs/2008A%26A...477....9H/abstract): Magnetic processes in a collapsing dense core I.\n",
    "\n",
    "2. [Hennebelle and Teyssier 2008](https://ui.adsabs.harvard.edu/abs/2008A%26A...477...25H/abstract): Magnetic processes in a collapsing dense core II.\n",
    "\n",
    "3. [Commerçon et al. 2010](https://ui.adsabs.harvard.edu/abs/2010ASPC..429...66C/abstract): Protostellar collapse: radiative and magnetic feedbacks on small-scale fragmentation\n",
    "\n",
    "4. [González et al. 2015](https://ui.adsabs.harvard.edu/abs/2015A%26A...578A..12G/abstract): Multigroup radiation hydrodynamics with flux-limited diffusion and adaptive mesh refinement\n",
    "\n",
    "5. [Vaytet et al. 2018](https://ui.adsabs.harvard.edu/abs/2018A%26A...615A...5V/abstract):  Protostellar birth with ambipolar and ohmic diffusion \n",
    "\n",
    "6. [Hennebelle et al. 2020](https://ui.adsabs.harvard.edu/abs/2020A%26A...635A..67H/abstract):  What determines the formation and characteristics of protoplanetary discs? \n",
    "\n",
    "7. [Lebreuilly et al. 2020](https://ui.adsabs.harvard.edu/abs/2020A%26A...641A.112L/abstract): Protostellar collapse: the conditions to form dust-rich protoplanetary disks\n",
    "\n",
    "8. [Mignon-Risse et al. 2021](https://ui.adsabs.harvard.edu/abs/2021A%26A...652A..69M/abstract): Collapse of turbulent massive cores with ambipolar diffusion and hybrid radiative transfer. I. Accretion and multiplicity\n",
    "\n",
    "10. [Mignon-Risse et al. 2021](https://ui.adsabs.harvard.edu/abs/2021A%26A...656A..85M/abstract): Collapse of turbulent massive cores with ambipolar diffusion and hybrid radiative transfer. II. Outflows \n",
    "\n",
    "11. [Hennebelle et al. 2022](https://ui.adsabs.harvard.edu/abs/2022A%26A...668A.147H/abstract):  Influence of magnetic field and stellar radiative feedback on the collapse and the stellar mass spectrum of a massive star-forming clump \n",
    "\n",
    "12. [Commerçon et al. 2022](https://ui.adsabs.harvard.edu/abs/2022A%26A...658A..52C/abstract): Discs and outflows in the early phases of massive star formation: Influence of magnetic fields and ambipolar diffusion\n",
    "\n",
    "13. [Lebreuilly et al. 2024](https://ui.adsabs.harvard.edu/abs/2024A%26A...682A..30L/abstract): Synthetic populations of protoplanetary disks: Impact of magnetic fields and radiative transfer\n",
    "\n",
    "14. [Commerçon et al. 2024](https://ui.adsabs.harvard.edu/abs/2024A%26A...689L...9C/abstract): Discs are born eccentric"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
